\documentclass{standalone}
% preamble: usepackage, etc.
\begin{document}
	
\chapter{全文总结与展望}

\section{全文总结}

以增量学习的相关技术为基础，构建快速建模、具备持续快速更新能力的模型是当前大数据时代对数据处理的需求，也是未来自动化、智能化发展的有效途径。ELM的产生顺应了分析任务在快速建模和更新方面的需求，随着近年来的发展，其相关理论和应用也逐渐完善。为了探索更符合当前数据发展背景需要的增量学习算法，论文以ELM为基础理论工具，针对数据增量的场景下的模型学习和更新问题进行了研究。

在归纳分析当前ELM的相关理论、增量学习算法和对应的应用问题上的改进思路后，论文分别就具备结构增量的在线学习算法、具备不平衡数据学习的在线学习算法，以及混合数据变化下的在线学习算法三方面内容进行了研究。
从研究内容上看，论文都是围绕数据增量过程中的在线更新算法展开的研究。从建模方式上看，论文分别从有监督学习模型到半监督学习模型两方面进行探索。具体来讲，论文研究的主要内容和取得的主要研究成果包含以下三个方面：
\begin{enumerate}[labelsep = .5em, leftmargin = 0pt, itemindent = 3.8em]
\item[(1)]在对ELM相关分析和总结的基础之上，论文在针对数据增量的ELM模型基础之上，
结合结构增量的算法提出了OSIELM。论文除了结合ELM的两类增量学习算法外，还在求解过程中加入分块矩阵的广义逆矩阵进行求解。为了验证所提方法的有效性，论文分别在常用分类、回归问题，以及城市交通流数据的预测问题上进行了实验，对应的实验结果分别从小数据集到大数据集、从不同
应用问题的角度表明了论文所提方法的有效性。
\item[(2)]在进一步研究具体数据特点带来的增量学习模型的过程中，论文以气体传感器漂移补偿为背景，针对数据所呈现的不平衡学习问题，结合现有半监督学习模型进行了改进。其中，论文在不平衡学习问题上首先设计了聚类辅助的
样本选择算法，并在此基础上提出了WDTELM。在此基础之上，
论文进一步推导了未标记数据增加的场景下对应的在线学习算法OWDTELM。通过在气体传感器数据集上的验证实验表明，所提算法在标记样本较少时也能以较高的正确率工作，而相应的学习算法能以增量的方式快速更新，并具备和离线算法相近的分类正确率。
\item[(3)]为了适应混合数据增量下的在线学习问题，论文进一步提出了ODAELM-S和ODAELM-T两类在线学习模型。不同于现有的与ELM相关的半监督在线算法研究，这两类方法涉及的增量过程不仅限于标记和未标记数据的增量，
还涉及对应的减量学习，以及未标记数据到标记数据变化所带来的增量/减量学习。
在实验验证方面，论文通过三种不同的实验设置分别定量和定性地对比了ODAELM-S、ODAELM-T和其他几种分类算法的分类性能。
实验结果表明，论文所提的在线算法在更新时间上远优于改进前的批处理算法，
并且相较于OWDTELM来说，ODAELM-S和ODAELM-T能保持模型在半监督学习下的各种数据变化下都能进行对应的在线更新。
%在实验验证方面，论文在传感器数据集上模拟了一项定量实验和两项定性实验。其中，定量实验说明了论文所提在线算法在时间效益上远优于改进前的批处理算法，而两类定性实验通过模拟两种样本筛选策略下的分类性能，从而进一步说明了所提在线算法在保持甚至超越了改进前离线算法的分类性能的同时，还具有更好的时间和成本效益。
\end{enumerate}

最后，作为当前研究内容的延伸，论文在后续工作展望里对当前工作的内容和所涉及算法的局限性进行了归纳和总结。针对可能存在的问题和当前研究所未能涵盖的内容，论文进行了展望，列举了可能的研究方向和应用领域。


%陈述本文的局限性
%时序模型研究的不多，对时序预测场景的研究不足
%对图像、视频、语音和自然语言等领域的内容没有涉猎
%列举图像的成果和遇到的问题，作为后续工作

\section{后续工作展望}
增量学习的相关研究是一个大范畴的领域，尤其是在当下应用和数据飞速发展的时代，针对特定问题的算法模型改进各不相同。论文基于ELM相关理论，以数据增量构建在线学习模型取得了一定研究成果，但同时存在着一定局限性。
针对目前的研究内容所未能涵盖的部分，论文总结了四个方面的局限性，作为后续研究开展的线索和依据。
\begin{enumerate}[labelsep = .5em, leftmargin = 0pt, itemindent = 3.8em]
\item[(1)] 针对增量学习另外两类的研究，即类别增量和数据属性增量的研究在本文中没有涉及。从经典ELM模型来看，类别或是数据属性的增加不仅仅对应着输入或是输出节点的增加。优化目标中包含的约束关系，乃至输出层节点之间的关系都可能随之发生变化。此外，经典的ELM的优化目标基于经验误差最小化，在ANN的众多优化目标函数中，针对不同的问题还存在更加合适的替换方案。
\item[(2)] 从学习算法来看，当前的研究覆盖了有监督学习和半监督学习领域，针对无监督学习任务，
以及混合数据增量场景下的其他建模问题还有待深入。在研究结合领域自适应的半监督算法过程中，标记样本的筛选和标记过程不仅受限于具体应用场景，还受限于是否具备足够的时间、人力和物力资源来完成这样的过程。现有的基于ELM的无监督学习算法一方面是通过迁移学习的方式从有标签的相关数据中进行模型的重调，另一类是通过堆叠自编码机的方式来实现。
后续在以无监督学习方式构建基于ELM的增量学习的研究将围绕这部分内容展开。
\item[(3)] 从结构上来看，ELM还属于相对简单的模型，在处理复杂任务，尤其是在大型系统中，还有必要结合更加复杂的分析模型和结构。虽然经典ELM的提出是以三层结构来简化ANN的训练，同时保持良好的分类/回归性能。但随着相关研究的深入开展，相关研究者为了保持更好的泛化性或是特定应用处理的需要，也会采用多层或是更加复杂的非循环结构。
\item[(4)] 从处理的数据类型上来看，论文主要针对的是经过预处理后形成的结构化的文本数据，对其他类型数据的分析建模还有待深入。在针对具体应用场景的建模过程中，论文针对图像分类问题尝试过结合领域自适应的思路，通过在标记数据上训练特征映射和分类器，再在未标记的图像数据上以对抗学习来重新调整特征映射的方式实现无监督的分类器训练。该研究尝试以CNN网络来做特征提取，通过堆叠ELM来实现特征的二次变换，在调整特征的时候保持CNN不变，而增量式地调整ELM部分的结构。从目前对该部分还不完善的实验数据的分析来看，以ELM来构建特征映射并不是一件堆叠简单结构的问题。ELM从本质上还属于广义线性模型的范畴，而实际面临的数据分布可能存在复杂的非线性特征，
这一特点并不一定能以简单的ELM单隐藏层结构进行有效表示。因此，单纯ELM或是ELM的堆叠很可能并不能从根本上替代深度学习模型来实现快速的训练和更新。类似的，在处理诸如视频数据、语音数据或是自然语言处理等问题上，也可能面临类似的问题。
\end{enumerate}



\end{document}